{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at modeling equations; and using pytorch + fastai for general numerical tasks.\n",
    "\n",
    "WNixalo â€“ 2018/6/25 (WiP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Force(m,a):\n",
    "    return m*a\n",
    "\n",
    "def mass(F,a):\n",
    "    if a == 0: return np.inf\n",
    "    return F/a\n",
    "\n",
    "def accel(F,m):\n",
    "    if F == 0: return np.inf\n",
    "    return m/F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = {'F':Force, 'm':mass, 'a':accel}\n",
    "vals = defaultdict(list)\n",
    "for fn in fns:\n",
    "    vals[fn] = [[[f'{i},{j}', fns[fn](i,j)] for j in range(20)] for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []; y = []\n",
    "fn_modes = ['F','m','a']\n",
    "for i,f in enumerate(fn_modes):\n",
    "    for val in vals[f]:\n",
    "        for v in val:\n",
    "            args,out = v\n",
    "            args = [int(a) for a in args.split(',')]\n",
    "            args = [i, *args]\n",
    "            x.append(args)\n",
    "            y.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 10, 0],\n",
       " [2, 10, 1],\n",
       " [2, 10, 2],\n",
       " [2, 10, 3],\n",
       " [2, 10, 4],\n",
       " [2, 10, 5],\n",
       " [2, 10, 6],\n",
       " [2, 10, 7],\n",
       " [2, 10, 8],\n",
       " [2, 10, 9]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc0 = nn.Linear(3, 20)\n",
    "        self.fc1 = nn.Linear(20,1)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc0(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = F.binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.FloatTensor(x[0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        assert len(x) == len(y)\n",
    "        self.transform = None\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, i):\n",
    "        return torch.FloatTensor(self.x[i]), torch.FloatTensor([self.y[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NumDataset(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.,  0.,  0.]), tensor([ 0.]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ModelData.from_dls(Path(os.getcwd())/'data', train_loader, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.,   0.,   0.],\n",
       "         [  0.,   0.,   1.],\n",
       "         [  0.,   0.,   2.],\n",
       "         [  0.,   0.,   3.],\n",
       "         [  0.,   0.,   4.],\n",
       "         [  0.,   0.,   5.],\n",
       "         [  0.,   0.,   6.],\n",
       "         [  0.,   0.,   7.],\n",
       "         [  0.,   0.,   8.],\n",
       "         [  0.,   0.,   9.],\n",
       "         [  0.,   0.,  10.],\n",
       "         [  0.,   0.,  11.],\n",
       "         [  0.,   0.,  12.],\n",
       "         [  0.,   0.,  13.],\n",
       "         [  0.,   0.,  14.],\n",
       "         [  0.,   0.,  15.]]), tensor([[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(md.trn_dl))\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner.from_model_data(NN(), md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(z, y):\n",
    "#     if y != 0:\n",
    "#         return torch.abs((z-y)/y)\n",
    "#     else:\n",
    "#         return torch.min(1.0, torch.abs(z-y))\n",
    "    return torch.abs((z-y)/y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.crit = loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23c20478e2247798ef3f4fab125b94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/75 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-f672079ce412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_skip_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Deshar/Kaukasos/pytorch/fastai/learner.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, wds, linear, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR_Finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Deshar/Kaukasos/pytorch/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Deshar/Kaukasos/pytorch/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;31m# pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Deshar/Kaukasos/pytorch/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdate_fp32_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Miniconda3/envs/fastai/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Miniconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Miniconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.sched.plot(n_skip_end=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0496],\n",
       "         [ 0.1746],\n",
       "         [ 0.3986],\n",
       "         [ 0.6396],\n",
       "         [ 0.8646],\n",
       "         [ 1.0819],\n",
       "         [ 1.2992],\n",
       "         [ 1.5165],\n",
       "         [ 1.7338],\n",
       "         [ 1.9511],\n",
       "         [ 2.1684],\n",
       "         [ 2.3857],\n",
       "         [ 2.6030],\n",
       "         [ 2.8202],\n",
       "         [ 3.0375],\n",
       "         [ 3.2548]]), tensor([[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.model(x), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8740)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.crit(learner.model(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b66a92c76d46629cd809dd7bec0b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      nan        nan       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(1e-10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = learner.data.val_ds.x\n",
    "y = learner.data.val_ds.y\n",
    "z = learner.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.model(torch.Tensor([[1,3,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0] : [0.] : 0\n",
      "[0, 0, 1] : [0.] : 0\n",
      "[0, 0, 2] : [0.] : 0\n",
      "[0, 0, 3] : [0.] : 0\n",
      "[0, 0, 4] : [0.] : 0\n",
      "[0, 0, 5] : [0.] : 0\n",
      "[0, 0, 6] : [0.] : 0\n",
      "[0, 0, 7] : [0.] : 0\n",
      "[0, 0, 8] : [0.] : 0\n",
      "[0, 0, 9] : [0.] : 0\n",
      "[0, 0, 10] : [0.] : 0\n",
      "[0, 0, 11] : [0.] : 0\n",
      "[0, 0, 12] : [0.] : 0\n",
      "[0, 0, 13] : [0.] : 0\n",
      "[0, 0, 14] : [0.] : 0\n",
      "[0, 0, 15] : [0.] : 0\n",
      "[0, 0, 16] : [0.] : 0\n",
      "[0, 0, 17] : [0.] : 0\n",
      "[0, 0, 18] : [0.] : 0\n",
      "[0, 0, 19] : [0.] : 0\n",
      "[0, 1, 0] : [0.] : 0\n",
      "[0, 1, 1] : [0.] : 1\n",
      "[0, 1, 2] : [0.] : 2\n",
      "[0, 1, 3] : [0.] : 3\n",
      "[0, 1, 4] : [0.] : 4\n",
      "[0, 1, 5] : [0.] : 5\n",
      "[0, 1, 6] : [0.] : 6\n",
      "[0, 1, 7] : [0.] : 7\n",
      "[0, 1, 8] : [0.] : 8\n",
      "[0, 1, 9] : [0.] : 9\n",
      "[0, 1, 10] : [0.] : 10\n",
      "[0, 1, 11] : [0.] : 11\n",
      "[0, 1, 12] : [0.] : 12\n",
      "[0, 1, 13] : [0.] : 13\n",
      "[0, 1, 14] : [0.] : 14\n",
      "[0, 1, 15] : [0.] : 15\n",
      "[0, 1, 16] : [0.] : 16\n",
      "[0, 1, 17] : [0.] : 17\n",
      "[0, 1, 18] : [0.] : 18\n",
      "[0, 1, 19] : [0.] : 19\n",
      "[0, 2, 0] : [0.] : 0\n",
      "[0, 2, 1] : [0.] : 2\n",
      "[0, 2, 2] : [0.] : 4\n",
      "[0, 2, 3] : [0.] : 6\n",
      "[0, 2, 4] : [0.] : 8\n",
      "[0, 2, 5] : [0.] : 10\n",
      "[0, 2, 6] : [0.] : 12\n",
      "[0, 2, 7] : [0.] : 14\n",
      "[0, 2, 8] : [0.] : 16\n",
      "[0, 2, 9] : [0.] : 18\n",
      "[0, 2, 10] : [0.] : 20\n",
      "[0, 2, 11] : [0.] : 22\n",
      "[0, 2, 12] : [0.] : 24\n",
      "[0, 2, 13] : [0.] : 26\n",
      "[0, 2, 14] : [0.] : 28\n",
      "[0, 2, 15] : [0.] : 30\n",
      "[0, 2, 16] : [0.] : 32\n",
      "[0, 2, 17] : [0.] : 34\n",
      "[0, 2, 18] : [0.] : 36\n",
      "[0, 2, 19] : [0.] : 38\n",
      "[0, 3, 0] : [0.] : 0\n",
      "[0, 3, 1] : [0.] : 3\n",
      "[0, 3, 2] : [0.] : 6\n",
      "[0, 3, 3] : [0.] : 9\n",
      "[0, 3, 4] : [0.] : 12\n",
      "[0, 3, 5] : [0.] : 15\n",
      "[0, 3, 6] : [0.] : 18\n",
      "[0, 3, 7] : [0.] : 21\n",
      "[0, 3, 8] : [0.] : 24\n",
      "[0, 3, 9] : [0.] : 27\n",
      "[0, 3, 10] : [0.] : 30\n",
      "[0, 3, 11] : [0.] : 33\n",
      "[0, 3, 12] : [0.] : 36\n",
      "[0, 3, 13] : [0.] : 39\n",
      "[0, 3, 14] : [0.] : 42\n",
      "[0, 3, 15] : [0.] : 45\n",
      "[0, 3, 16] : [0.] : 48\n",
      "[0, 3, 17] : [0.] : 51\n",
      "[0, 3, 18] : [0.] : 54\n",
      "[0, 3, 19] : [0.] : 57\n",
      "[0, 4, 0] : [0.] : 0\n",
      "[0, 4, 1] : [0.] : 4\n",
      "[0, 4, 2] : [0.] : 8\n",
      "[0, 4, 3] : [0.] : 12\n",
      "[0, 4, 4] : [0.] : 16\n",
      "[0, 4, 5] : [0.] : 20\n",
      "[0, 4, 6] : [0.] : 24\n",
      "[0, 4, 7] : [0.] : 28\n",
      "[0, 4, 8] : [0.] : 32\n",
      "[0, 4, 9] : [0.] : 36\n",
      "[0, 4, 10] : [0.] : 40\n",
      "[0, 4, 11] : [0.] : 44\n",
      "[0, 4, 12] : [0.] : 48\n",
      "[0, 4, 13] : [0.] : 52\n",
      "[0, 4, 14] : [0.] : 56\n",
      "[0, 4, 15] : [0.] : 60\n",
      "[0, 4, 16] : [0.] : 64\n",
      "[0, 4, 17] : [0.] : 68\n",
      "[0, 4, 18] : [0.] : 72\n",
      "[0, 4, 19] : [0.] : 76\n",
      "[0, 5, 0] : [0.] : 0\n",
      "[0, 5, 1] : [0.] : 5\n",
      "[0, 5, 2] : [0.] : 10\n",
      "[0, 5, 3] : [0.] : 15\n",
      "[0, 5, 4] : [0.] : 20\n",
      "[0, 5, 5] : [0.] : 25\n",
      "[0, 5, 6] : [0.] : 30\n",
      "[0, 5, 7] : [0.] : 35\n",
      "[0, 5, 8] : [0.] : 40\n",
      "[0, 5, 9] : [0.] : 45\n",
      "[0, 5, 10] : [0.] : 50\n",
      "[0, 5, 11] : [0.] : 55\n",
      "[0, 5, 12] : [0.] : 60\n",
      "[0, 5, 13] : [0.] : 65\n",
      "[0, 5, 14] : [0.] : 70\n",
      "[0, 5, 15] : [0.] : 75\n",
      "[0, 5, 16] : [0.] : 80\n",
      "[0, 5, 17] : [0.] : 85\n",
      "[0, 5, 18] : [0.] : 90\n",
      "[0, 5, 19] : [0.] : 95\n",
      "[0, 6, 0] : [0.] : 0\n",
      "[0, 6, 1] : [0.] : 6\n",
      "[0, 6, 2] : [0.] : 12\n",
      "[0, 6, 3] : [0.] : 18\n",
      "[0, 6, 4] : [0.] : 24\n",
      "[0, 6, 5] : [0.] : 30\n",
      "[0, 6, 6] : [0.] : 36\n",
      "[0, 6, 7] : [0.] : 42\n",
      "[0, 6, 8] : [0.] : 48\n",
      "[0, 6, 9] : [0.] : 54\n",
      "[0, 6, 10] : [0.] : 60\n",
      "[0, 6, 11] : [0.] : 66\n",
      "[0, 6, 12] : [0.] : 72\n",
      "[0, 6, 13] : [0.] : 78\n",
      "[0, 6, 14] : [0.] : 84\n",
      "[0, 6, 15] : [0.] : 90\n",
      "[0, 6, 16] : [0.] : 96\n",
      "[0, 6, 17] : [0.] : 102\n",
      "[0, 6, 18] : [0.] : 108\n",
      "[0, 6, 19] : [0.] : 114\n",
      "[0, 7, 0] : [0.] : 0\n",
      "[0, 7, 1] : [0.] : 7\n",
      "[0, 7, 2] : [0.] : 14\n",
      "[0, 7, 3] : [0.] : 21\n",
      "[0, 7, 4] : [0.] : 28\n",
      "[0, 7, 5] : [0.] : 35\n",
      "[0, 7, 6] : [0.] : 42\n",
      "[0, 7, 7] : [0.] : 49\n",
      "[0, 7, 8] : [0.] : 56\n",
      "[0, 7, 9] : [0.] : 63\n",
      "[0, 7, 10] : [0.] : 70\n",
      "[0, 7, 11] : [0.] : 77\n",
      "[0, 7, 12] : [0.] : 84\n",
      "[0, 7, 13] : [0.] : 91\n",
      "[0, 7, 14] : [0.] : 98\n",
      "[0, 7, 15] : [0.] : 105\n",
      "[0, 7, 16] : [0.] : 112\n",
      "[0, 7, 17] : [0.] : 119\n",
      "[0, 7, 18] : [0.] : 126\n",
      "[0, 7, 19] : [0.] : 133\n",
      "[0, 8, 0] : [0.] : 0\n",
      "[0, 8, 1] : [0.] : 8\n",
      "[0, 8, 2] : [0.] : 16\n",
      "[0, 8, 3] : [0.] : 24\n",
      "[0, 8, 4] : [0.] : 32\n",
      "[0, 8, 5] : [0.] : 40\n",
      "[0, 8, 6] : [0.] : 48\n",
      "[0, 8, 7] : [0.] : 56\n",
      "[0, 8, 8] : [0.] : 64\n",
      "[0, 8, 9] : [0.] : 72\n",
      "[0, 8, 10] : [0.] : 80\n",
      "[0, 8, 11] : [0.] : 88\n",
      "[0, 8, 12] : [0.] : 96\n",
      "[0, 8, 13] : [0.] : 104\n",
      "[0, 8, 14] : [0.] : 112\n",
      "[0, 8, 15] : [0.] : 120\n",
      "[0, 8, 16] : [0.] : 128\n",
      "[0, 8, 17] : [0.] : 136\n",
      "[0, 8, 18] : [0.] : 144\n",
      "[0, 8, 19] : [0.] : 152\n",
      "[0, 9, 0] : [0.] : 0\n",
      "[0, 9, 1] : [0.] : 9\n",
      "[0, 9, 2] : [0.] : 18\n",
      "[0, 9, 3] : [0.] : 27\n",
      "[0, 9, 4] : [0.] : 36\n",
      "[0, 9, 5] : [0.] : 45\n",
      "[0, 9, 6] : [0.] : 54\n",
      "[0, 9, 7] : [0.] : 63\n",
      "[0, 9, 8] : [0.] : 72\n",
      "[0, 9, 9] : [0.] : 81\n",
      "[0, 9, 10] : [0.] : 90\n",
      "[0, 9, 11] : [0.] : 99\n",
      "[0, 9, 12] : [0.] : 108\n",
      "[0, 9, 13] : [0.] : 117\n",
      "[0, 9, 14] : [0.] : 126\n",
      "[0, 9, 15] : [0.] : 135\n",
      "[0, 9, 16] : [0.] : 144\n",
      "[0, 9, 17] : [0.] : 153\n",
      "[0, 9, 18] : [0.] : 162\n",
      "[0, 9, 19] : [0.] : 171\n",
      "[0, 10, 0] : [0.] : 0\n",
      "[0, 10, 1] : [0.] : 10\n",
      "[0, 10, 2] : [0.] : 20\n",
      "[0, 10, 3] : [0.] : 30\n",
      "[0, 10, 4] : [0.] : 40\n",
      "[0, 10, 5] : [0.] : 50\n",
      "[0, 10, 6] : [0.] : 60\n",
      "[0, 10, 7] : [0.] : 70\n",
      "[0, 10, 8] : [0.] : 80\n",
      "[0, 10, 9] : [0.] : 90\n",
      "[0, 10, 10] : [0.] : 100\n",
      "[0, 10, 11] : [0.] : 110\n",
      "[0, 10, 12] : [0.] : 120\n",
      "[0, 10, 13] : [0.] : 130\n",
      "[0, 10, 14] : [0.] : 140\n",
      "[0, 10, 15] : [0.] : 150\n",
      "[0, 10, 16] : [0.] : 160\n",
      "[0, 10, 17] : [0.] : 170\n",
      "[0, 10, 18] : [0.] : 180\n",
      "[0, 10, 19] : [0.] : 190\n",
      "[0, 11, 0] : [0.] : 0\n",
      "[0, 11, 1] : [0.] : 11\n",
      "[0, 11, 2] : [0.] : 22\n",
      "[0, 11, 3] : [0.] : 33\n",
      "[0, 11, 4] : [0.] : 44\n",
      "[0, 11, 5] : [0.] : 55\n",
      "[0, 11, 6] : [0.] : 66\n",
      "[0, 11, 7] : [0.] : 77\n",
      "[0, 11, 8] : [0.] : 88\n",
      "[0, 11, 9] : [0.] : 99\n",
      "[0, 11, 10] : [0.] : 110\n",
      "[0, 11, 11] : [0.] : 121\n",
      "[0, 11, 12] : [0.] : 132\n",
      "[0, 11, 13] : [0.] : 143\n",
      "[0, 11, 14] : [0.] : 154\n",
      "[0, 11, 15] : [0.] : 165\n",
      "[0, 11, 16] : [0.] : 176\n",
      "[0, 11, 17] : [0.] : 187\n",
      "[0, 11, 18] : [0.] : 198\n",
      "[0, 11, 19] : [0.] : 209\n",
      "[0, 12, 0] : [0.] : 0\n",
      "[0, 12, 1] : [0.] : 12\n",
      "[0, 12, 2] : [0.] : 24\n",
      "[0, 12, 3] : [0.] : 36\n",
      "[0, 12, 4] : [0.] : 48\n",
      "[0, 12, 5] : [0.] : 60\n",
      "[0, 12, 6] : [0.] : 72\n",
      "[0, 12, 7] : [0.] : 84\n",
      "[0, 12, 8] : [0.] : 96\n",
      "[0, 12, 9] : [0.] : 108\n",
      "[0, 12, 10] : [0.] : 120\n",
      "[0, 12, 11] : [0.] : 132\n",
      "[0, 12, 12] : [0.] : 144\n",
      "[0, 12, 13] : [0.] : 156\n",
      "[0, 12, 14] : [0.] : 168\n",
      "[0, 12, 15] : [0.] : 180\n",
      "[0, 12, 16] : [0.] : 192\n",
      "[0, 12, 17] : [0.] : 204\n",
      "[0, 12, 18] : [0.] : 216\n",
      "[0, 12, 19] : [0.] : 228\n",
      "[0, 13, 0] : [0.] : 0\n",
      "[0, 13, 1] : [0.] : 13\n",
      "[0, 13, 2] : [0.] : 26\n",
      "[0, 13, 3] : [0.] : 39\n",
      "[0, 13, 4] : [0.] : 52\n",
      "[0, 13, 5] : [0.] : 65\n",
      "[0, 13, 6] : [0.] : 78\n",
      "[0, 13, 7] : [0.] : 91\n",
      "[0, 13, 8] : [0.] : 104\n",
      "[0, 13, 9] : [0.] : 117\n",
      "[0, 13, 10] : [0.] : 130\n",
      "[0, 13, 11] : [0.] : 143\n",
      "[0, 13, 12] : [0.] : 156\n",
      "[0, 13, 13] : [0.] : 169\n",
      "[0, 13, 14] : [0.] : 182\n",
      "[0, 13, 15] : [0.] : 195\n",
      "[0, 13, 16] : [0.] : 208\n",
      "[0, 13, 17] : [0.] : 221\n",
      "[0, 13, 18] : [0.] : 234\n",
      "[0, 13, 19] : [0.] : 247\n",
      "[0, 14, 0] : [0.] : 0\n",
      "[0, 14, 1] : [0.] : 14\n",
      "[0, 14, 2] : [0.] : 28\n",
      "[0, 14, 3] : [0.] : 42\n",
      "[0, 14, 4] : [0.] : 56\n",
      "[0, 14, 5] : [0.] : 70\n",
      "[0, 14, 6] : [0.] : 84\n",
      "[0, 14, 7] : [0.] : 98\n",
      "[0, 14, 8] : [0.] : 112\n",
      "[0, 14, 9] : [0.] : 126\n",
      "[0, 14, 10] : [0.] : 140\n",
      "[0, 14, 11] : [0.] : 154\n",
      "[0, 14, 12] : [0.] : 168\n",
      "[0, 14, 13] : [0.] : 182\n",
      "[0, 14, 14] : [0.] : 196\n",
      "[0, 14, 15] : [0.] : 210\n",
      "[0, 14, 16] : [0.] : 224\n",
      "[0, 14, 17] : [0.] : 238\n",
      "[0, 14, 18] : [0.] : 252\n",
      "[0, 14, 19] : [0.] : 266\n",
      "[0, 15, 0] : [0.] : 0\n",
      "[0, 15, 1] : [0.] : 15\n",
      "[0, 15, 2] : [0.] : 30\n",
      "[0, 15, 3] : [0.] : 45\n",
      "[0, 15, 4] : [0.] : 60\n",
      "[0, 15, 5] : [0.] : 75\n",
      "[0, 15, 6] : [0.] : 90\n",
      "[0, 15, 7] : [0.] : 105\n",
      "[0, 15, 8] : [0.] : 120\n",
      "[0, 15, 9] : [0.] : 135\n",
      "[0, 15, 10] : [0.] : 150\n",
      "[0, 15, 11] : [0.] : 165\n",
      "[0, 15, 12] : [0.] : 180\n",
      "[0, 15, 13] : [0.] : 195\n",
      "[0, 15, 14] : [0.] : 210\n",
      "[0, 15, 15] : [0.] : 225\n",
      "[0, 15, 16] : [0.] : 240\n",
      "[0, 15, 17] : [0.] : 255\n",
      "[0, 15, 18] : [0.] : 270\n",
      "[0, 15, 19] : [0.] : 285\n",
      "[0, 16, 0] : [0.] : 0\n",
      "[0, 16, 1] : [0.] : 16\n",
      "[0, 16, 2] : [0.] : 32\n",
      "[0, 16, 3] : [0.] : 48\n",
      "[0, 16, 4] : [0.] : 64\n",
      "[0, 16, 5] : [0.] : 80\n",
      "[0, 16, 6] : [0.] : 96\n",
      "[0, 16, 7] : [0.] : 112\n",
      "[0, 16, 8] : [0.] : 128\n",
      "[0, 16, 9] : [0.] : 144\n",
      "[0, 16, 10] : [0.] : 160\n",
      "[0, 16, 11] : [0.] : 176\n",
      "[0, 16, 12] : [0.] : 192\n",
      "[0, 16, 13] : [0.] : 208\n",
      "[0, 16, 14] : [0.] : 224\n",
      "[0, 16, 15] : [0.] : 240\n",
      "[0, 16, 16] : [0.] : 256\n",
      "[0, 16, 17] : [0.] : 272\n",
      "[0, 16, 18] : [0.] : 288\n",
      "[0, 16, 19] : [0.] : 304\n",
      "[0, 17, 0] : [0.] : 0\n",
      "[0, 17, 1] : [0.] : 17\n",
      "[0, 17, 2] : [0.] : 34\n",
      "[0, 17, 3] : [0.] : 51\n",
      "[0, 17, 4] : [0.] : 68\n",
      "[0, 17, 5] : [0.] : 85\n",
      "[0, 17, 6] : [0.] : 102\n",
      "[0, 17, 7] : [0.] : 119\n",
      "[0, 17, 8] : [0.] : 136\n",
      "[0, 17, 9] : [0.] : 153\n",
      "[0, 17, 10] : [0.] : 170\n",
      "[0, 17, 11] : [0.] : 187\n",
      "[0, 17, 12] : [0.] : 204\n",
      "[0, 17, 13] : [0.] : 221\n",
      "[0, 17, 14] : [0.] : 238\n",
      "[0, 17, 15] : [0.] : 255\n",
      "[0, 17, 16] : [0.] : 272\n",
      "[0, 17, 17] : [0.] : 289\n",
      "[0, 17, 18] : [0.] : 306\n",
      "[0, 17, 19] : [0.] : 323\n",
      "[0, 18, 0] : [0.] : 0\n",
      "[0, 18, 1] : [0.] : 18\n",
      "[0, 18, 2] : [0.] : 36\n",
      "[0, 18, 3] : [0.] : 54\n",
      "[0, 18, 4] : [0.] : 72\n",
      "[0, 18, 5] : [0.] : 90\n",
      "[0, 18, 6] : [0.] : 108\n",
      "[0, 18, 7] : [0.] : 126\n",
      "[0, 18, 8] : [0.] : 144\n",
      "[0, 18, 9] : [0.] : 162\n",
      "[0, 18, 10] : [0.] : 180\n",
      "[0, 18, 11] : [0.] : 198\n",
      "[0, 18, 12] : [0.] : 216\n",
      "[0, 18, 13] : [0.] : 234\n",
      "[0, 18, 14] : [0.] : 252\n",
      "[0, 18, 15] : [0.] : 270\n",
      "[0, 18, 16] : [0.] : 288\n",
      "[0, 18, 17] : [0.] : 306\n",
      "[0, 18, 18] : [0.] : 324\n",
      "[0, 18, 19] : [0.] : 342\n",
      "[0, 19, 0] : [0.] : 0\n",
      "[0, 19, 1] : [0.] : 19\n",
      "[0, 19, 2] : [0.] : 38\n",
      "[0, 19, 3] : [0.] : 57\n",
      "[0, 19, 4] : [0.] : 76\n",
      "[0, 19, 5] : [0.] : 95\n",
      "[0, 19, 6] : [0.] : 114\n",
      "[0, 19, 7] : [0.] : 133\n",
      "[0, 19, 8] : [0.] : 152\n",
      "[0, 19, 9] : [0.] : 171\n",
      "[0, 19, 10] : [0.] : 190\n",
      "[0, 19, 11] : [0.] : 209\n",
      "[0, 19, 12] : [0.] : 228\n",
      "[0, 19, 13] : [0.] : 247\n",
      "[0, 19, 14] : [0.] : 266\n",
      "[0, 19, 15] : [0.] : 285\n",
      "[0, 19, 16] : [0.] : 304\n",
      "[0, 19, 17] : [0.] : 323\n",
      "[0, 19, 18] : [0.] : 342\n",
      "[0, 19, 19] : [0.] : 361\n",
      "[1, 0, 0] : [0.] : inf\n",
      "[1, 0, 1] : [0.] : 0.0\n",
      "[1, 0, 2] : [0.] : 0.0\n",
      "[1, 0, 3] : [0.] : 0.0\n",
      "[1, 0, 4] : [0.] : 0.0\n",
      "[1, 0, 5] : [0.] : 0.0\n",
      "[1, 0, 6] : [0.] : 0.0\n",
      "[1, 0, 7] : [0.] : 0.0\n",
      "[1, 0, 8] : [0.] : 0.0\n",
      "[1, 0, 9] : [0.] : 0.0\n",
      "[1, 0, 10] : [0.] : 0.0\n",
      "[1, 0, 11] : [0.] : 0.0\n",
      "[1, 0, 12] : [0.] : 0.0\n",
      "[1, 0, 13] : [0.] : 0.0\n",
      "[1, 0, 14] : [0.] : 0.0\n",
      "[1, 0, 15] : [0.] : 0.0\n",
      "[1, 0, 16] : [0.] : 0.0\n",
      "[1, 0, 17] : [0.] : 0.0\n",
      "[1, 0, 18] : [0.] : 0.0\n",
      "[1, 0, 19] : [0.] : 0.0\n",
      "[1, 1, 0] : [0.] : inf\n",
      "[1, 1, 1] : [0.] : 1.0\n",
      "[1, 1, 2] : [0.] : 0.5\n",
      "[1, 1, 3] : [0.] : 0.3333333333333333\n",
      "[1, 1, 4] : [0.] : 0.25\n",
      "[1, 1, 5] : [0.] : 0.2\n",
      "[1, 1, 6] : [0.] : 0.16666666666666666\n",
      "[1, 1, 7] : [0.] : 0.14285714285714285\n",
      "[1, 1, 8] : [0.] : 0.125\n",
      "[1, 1, 9] : [0.] : 0.1111111111111111\n",
      "[1, 1, 10] : [0.] : 0.1\n",
      "[1, 1, 11] : [0.] : 0.09090909090909091\n",
      "[1, 1, 12] : [0.] : 0.08333333333333333\n",
      "[1, 1, 13] : [0.] : 0.07692307692307693\n",
      "[1, 1, 14] : [0.] : 0.07142857142857142\n",
      "[1, 1, 15] : [0.] : 0.06666666666666667\n",
      "[1, 1, 16] : [0.] : 0.0625\n",
      "[1, 1, 17] : [0.] : 0.058823529411764705\n",
      "[1, 1, 18] : [0.] : 0.05555555555555555\n",
      "[1, 1, 19] : [0.] : 0.05263157894736842\n",
      "[1, 2, 0] : [0.] : inf\n",
      "[1, 2, 1] : [0.] : 2.0\n",
      "[1, 2, 2] : [0.] : 1.0\n",
      "[1, 2, 3] : [0.] : 0.6666666666666666\n",
      "[1, 2, 4] : [0.] : 0.5\n",
      "[1, 2, 5] : [0.] : 0.4\n",
      "[1, 2, 6] : [0.] : 0.3333333333333333\n",
      "[1, 2, 7] : [0.] : 0.2857142857142857\n",
      "[1, 2, 8] : [0.] : 0.25\n",
      "[1, 2, 9] : [0.] : 0.2222222222222222\n",
      "[1, 2, 10] : [0.] : 0.2\n",
      "[1, 2, 11] : [0.] : 0.18181818181818182\n",
      "[1, 2, 12] : [0.] : 0.16666666666666666\n",
      "[1, 2, 13] : [0.] : 0.15384615384615385\n",
      "[1, 2, 14] : [0.] : 0.14285714285714285\n",
      "[1, 2, 15] : [0.] : 0.13333333333333333\n",
      "[1, 2, 16] : [0.] : 0.125\n",
      "[1, 2, 17] : [0.] : 0.11764705882352941\n",
      "[1, 2, 18] : [0.] : 0.1111111111111111\n",
      "[1, 2, 19] : [0.] : 0.10526315789473684\n",
      "[1, 3, 0] : [0.] : inf\n",
      "[1, 3, 1] : [0.] : 3.0\n",
      "[1, 3, 2] : [0.] : 1.5\n",
      "[1, 3, 3] : [0.] : 1.0\n",
      "[1, 3, 4] : [0.] : 0.75\n",
      "[1, 3, 5] : [0.] : 0.6\n",
      "[1, 3, 6] : [0.] : 0.5\n",
      "[1, 3, 7] : [0.] : 0.42857142857142855\n",
      "[1, 3, 8] : [0.] : 0.375\n",
      "[1, 3, 9] : [0.] : 0.3333333333333333\n",
      "[1, 3, 10] : [0.] : 0.3\n",
      "[1, 3, 11] : [0.] : 0.2727272727272727\n",
      "[1, 3, 12] : [0.] : 0.25\n",
      "[1, 3, 13] : [0.] : 0.23076923076923078\n",
      "[1, 3, 14] : [0.] : 0.21428571428571427\n",
      "[1, 3, 15] : [0.] : 0.2\n",
      "[1, 3, 16] : [0.] : 0.1875\n",
      "[1, 3, 17] : [0.] : 0.17647058823529413\n",
      "[1, 3, 18] : [0.] : 0.16666666666666666\n",
      "[1, 3, 19] : [0.] : 0.15789473684210525\n",
      "[1, 4, 0] : [0.] : inf\n",
      "[1, 4, 1] : [0.] : 4.0\n",
      "[1, 4, 2] : [0.] : 2.0\n",
      "[1, 4, 3] : [0.] : 1.3333333333333333\n",
      "[1, 4, 4] : [0.] : 1.0\n",
      "[1, 4, 5] : [0.] : 0.8\n",
      "[1, 4, 6] : [0.] : 0.6666666666666666\n",
      "[1, 4, 7] : [0.] : 0.5714285714285714\n",
      "[1, 4, 8] : [0.] : 0.5\n",
      "[1, 4, 9] : [0.] : 0.4444444444444444\n",
      "[1, 4, 10] : [0.] : 0.4\n",
      "[1, 4, 11] : [0.] : 0.36363636363636365\n",
      "[1, 4, 12] : [0.] : 0.3333333333333333\n",
      "[1, 4, 13] : [0.] : 0.3076923076923077\n",
      "[1, 4, 14] : [0.] : 0.2857142857142857\n",
      "[1, 4, 15] : [0.] : 0.26666666666666666\n",
      "[1, 4, 16] : [0.] : 0.25\n",
      "[1, 4, 17] : [0.] : 0.23529411764705882\n",
      "[1, 4, 18] : [0.] : 0.2222222222222222\n",
      "[1, 4, 19] : [0.] : 0.21052631578947367\n",
      "[1, 5, 0] : [0.] : inf\n",
      "[1, 5, 1] : [0.] : 5.0\n",
      "[1, 5, 2] : [0.] : 2.5\n",
      "[1, 5, 3] : [0.] : 1.6666666666666667\n",
      "[1, 5, 4] : [0.] : 1.25\n",
      "[1, 5, 5] : [0.] : 1.0\n",
      "[1, 5, 6] : [0.] : 0.8333333333333334\n",
      "[1, 5, 7] : [0.] : 0.7142857142857143\n",
      "[1, 5, 8] : [0.] : 0.625\n",
      "[1, 5, 9] : [0.] : 0.5555555555555556\n",
      "[1, 5, 10] : [0.] : 0.5\n",
      "[1, 5, 11] : [0.] : 0.45454545454545453\n",
      "[1, 5, 12] : [0.] : 0.4166666666666667\n",
      "[1, 5, 13] : [0.] : 0.38461538461538464\n",
      "[1, 5, 14] : [0.] : 0.35714285714285715\n",
      "[1, 5, 15] : [0.] : 0.3333333333333333\n",
      "[1, 5, 16] : [0.] : 0.3125\n",
      "[1, 5, 17] : [0.] : 0.29411764705882354\n",
      "[1, 5, 18] : [0.] : 0.2777777777777778\n",
      "[1, 5, 19] : [0.] : 0.2631578947368421\n",
      "[1, 6, 0] : [0.] : inf\n",
      "[1, 6, 1] : [0.] : 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 6, 2] : [0.] : 3.0\n",
      "[1, 6, 3] : [0.] : 2.0\n",
      "[1, 6, 4] : [0.] : 1.5\n",
      "[1, 6, 5] : [0.] : 1.2\n",
      "[1, 6, 6] : [0.] : 1.0\n",
      "[1, 6, 7] : [0.] : 0.8571428571428571\n",
      "[1, 6, 8] : [0.] : 0.75\n",
      "[1, 6, 9] : [0.] : 0.6666666666666666\n",
      "[1, 6, 10] : [0.] : 0.6\n",
      "[1, 6, 11] : [0.] : 0.5454545454545454\n",
      "[1, 6, 12] : [0.] : 0.5\n",
      "[1, 6, 13] : [0.] : 0.46153846153846156\n",
      "[1, 6, 14] : [0.] : 0.42857142857142855\n",
      "[1, 6, 15] : [0.] : 0.4\n",
      "[1, 6, 16] : [0.] : 0.375\n",
      "[1, 6, 17] : [0.] : 0.35294117647058826\n",
      "[1, 6, 18] : [0.] : 0.3333333333333333\n",
      "[1, 6, 19] : [0.] : 0.3157894736842105\n",
      "[1, 7, 0] : [0.] : inf\n",
      "[1, 7, 1] : [0.] : 7.0\n",
      "[1, 7, 2] : [0.] : 3.5\n",
      "[1, 7, 3] : [0.] : 2.3333333333333335\n",
      "[1, 7, 4] : [0.] : 1.75\n",
      "[1, 7, 5] : [0.] : 1.4\n",
      "[1, 7, 6] : [0.] : 1.1666666666666667\n",
      "[1, 7, 7] : [0.] : 1.0\n",
      "[1, 7, 8] : [0.] : 0.875\n",
      "[1, 7, 9] : [0.] : 0.7777777777777778\n",
      "[1, 7, 10] : [0.] : 0.7\n",
      "[1, 7, 11] : [0.] : 0.6363636363636364\n",
      "[1, 7, 12] : [0.] : 0.5833333333333334\n",
      "[1, 7, 13] : [0.] : 0.5384615384615384\n",
      "[1, 7, 14] : [0.] : 0.5\n",
      "[1, 7, 15] : [0.] : 0.4666666666666667\n",
      "[1, 7, 16] : [0.] : 0.4375\n",
      "[1, 7, 17] : [0.] : 0.4117647058823529\n",
      "[1, 7, 18] : [0.] : 0.3888888888888889\n",
      "[1, 7, 19] : [0.] : 0.3684210526315789\n",
      "[1, 8, 0] : [0.] : inf\n",
      "[1, 8, 1] : [0.] : 8.0\n",
      "[1, 8, 2] : [0.] : 4.0\n",
      "[1, 8, 3] : [0.] : 2.6666666666666665\n",
      "[1, 8, 4] : [0.] : 2.0\n",
      "[1, 8, 5] : [0.] : 1.6\n",
      "[1, 8, 6] : [0.] : 1.3333333333333333\n",
      "[1, 8, 7] : [0.] : 1.1428571428571428\n",
      "[1, 8, 8] : [0.] : 1.0\n",
      "[1, 8, 9] : [0.] : 0.8888888888888888\n",
      "[1, 8, 10] : [0.] : 0.8\n",
      "[1, 8, 11] : [0.] : 0.7272727272727273\n",
      "[1, 8, 12] : [0.] : 0.6666666666666666\n",
      "[1, 8, 13] : [0.] : 0.6153846153846154\n",
      "[1, 8, 14] : [0.] : 0.5714285714285714\n",
      "[1, 8, 15] : [0.] : 0.5333333333333333\n",
      "[1, 8, 16] : [0.] : 0.5\n",
      "[1, 8, 17] : [0.] : 0.47058823529411764\n",
      "[1, 8, 18] : [0.] : 0.4444444444444444\n",
      "[1, 8, 19] : [0.] : 0.42105263157894735\n",
      "[1, 9, 0] : [0.] : inf\n",
      "[1, 9, 1] : [0.] : 9.0\n",
      "[1, 9, 2] : [0.] : 4.5\n",
      "[1, 9, 3] : [0.] : 3.0\n",
      "[1, 9, 4] : [0.] : 2.25\n",
      "[1, 9, 5] : [0.] : 1.8\n",
      "[1, 9, 6] : [0.] : 1.5\n",
      "[1, 9, 7] : [0.] : 1.2857142857142858\n",
      "[1, 9, 8] : [0.] : 1.125\n",
      "[1, 9, 9] : [0.] : 1.0\n",
      "[1, 9, 10] : [0.] : 0.9\n",
      "[1, 9, 11] : [0.] : 0.8181818181818182\n",
      "[1, 9, 12] : [0.] : 0.75\n",
      "[1, 9, 13] : [0.] : 0.6923076923076923\n",
      "[1, 9, 14] : [0.] : 0.6428571428571429\n",
      "[1, 9, 15] : [0.] : 0.6\n",
      "[1, 9, 16] : [0.] : 0.5625\n",
      "[1, 9, 17] : [0.] : 0.5294117647058824\n",
      "[1, 9, 18] : [0.] : 0.5\n",
      "[1, 9, 19] : [0.] : 0.47368421052631576\n",
      "[1, 10, 0] : [0.] : inf\n",
      "[1, 10, 1] : [0.] : 10.0\n",
      "[1, 10, 2] : [0.] : 5.0\n",
      "[1, 10, 3] : [0.] : 3.3333333333333335\n",
      "[1, 10, 4] : [0.] : 2.5\n",
      "[1, 10, 5] : [0.] : 2.0\n",
      "[1, 10, 6] : [0.] : 1.6666666666666667\n",
      "[1, 10, 7] : [0.] : 1.4285714285714286\n",
      "[1, 10, 8] : [0.] : 1.25\n",
      "[1, 10, 9] : [0.] : 1.1111111111111112\n",
      "[1, 10, 10] : [0.] : 1.0\n",
      "[1, 10, 11] : [0.] : 0.9090909090909091\n",
      "[1, 10, 12] : [0.] : 0.8333333333333334\n",
      "[1, 10, 13] : [0.] : 0.7692307692307693\n",
      "[1, 10, 14] : [0.] : 0.7142857142857143\n",
      "[1, 10, 15] : [0.] : 0.6666666666666666\n",
      "[1, 10, 16] : [0.] : 0.625\n",
      "[1, 10, 17] : [0.] : 0.5882352941176471\n",
      "[1, 10, 18] : [0.] : 0.5555555555555556\n",
      "[1, 10, 19] : [0.] : 0.5263157894736842\n",
      "[1, 11, 0] : [0.] : inf\n",
      "[1, 11, 1] : [0.] : 11.0\n",
      "[1, 11, 2] : [0.] : 5.5\n",
      "[1, 11, 3] : [0.] : 3.6666666666666665\n",
      "[1, 11, 4] : [0.] : 2.75\n",
      "[1, 11, 5] : [0.] : 2.2\n",
      "[1, 11, 6] : [0.] : 1.8333333333333333\n",
      "[1, 11, 7] : [0.] : 1.5714285714285714\n",
      "[1, 11, 8] : [0.] : 1.375\n",
      "[1, 11, 9] : [0.] : 1.2222222222222223\n",
      "[1, 11, 10] : [0.] : 1.1\n",
      "[1, 11, 11] : [0.] : 1.0\n",
      "[1, 11, 12] : [0.] : 0.9166666666666666\n",
      "[1, 11, 13] : [0.] : 0.8461538461538461\n",
      "[1, 11, 14] : [0.] : 0.7857142857142857\n",
      "[1, 11, 15] : [0.] : 0.7333333333333333\n",
      "[1, 11, 16] : [0.] : 0.6875\n",
      "[1, 11, 17] : [0.] : 0.6470588235294118\n",
      "[1, 11, 18] : [0.] : 0.6111111111111112\n",
      "[1, 11, 19] : [0.] : 0.5789473684210527\n",
      "[1, 12, 0] : [0.] : inf\n",
      "[1, 12, 1] : [0.] : 12.0\n",
      "[1, 12, 2] : [0.] : 6.0\n",
      "[1, 12, 3] : [0.] : 4.0\n",
      "[1, 12, 4] : [0.] : 3.0\n",
      "[1, 12, 5] : [0.] : 2.4\n",
      "[1, 12, 6] : [0.] : 2.0\n",
      "[1, 12, 7] : [0.] : 1.7142857142857142\n",
      "[1, 12, 8] : [0.] : 1.5\n",
      "[1, 12, 9] : [0.] : 1.3333333333333333\n",
      "[1, 12, 10] : [0.] : 1.2\n",
      "[1, 12, 11] : [0.] : 1.0909090909090908\n",
      "[1, 12, 12] : [0.] : 1.0\n",
      "[1, 12, 13] : [0.] : 0.9230769230769231\n",
      "[1, 12, 14] : [0.] : 0.8571428571428571\n",
      "[1, 12, 15] : [0.] : 0.8\n",
      "[1, 12, 16] : [0.] : 0.75\n",
      "[1, 12, 17] : [0.] : 0.7058823529411765\n",
      "[1, 12, 18] : [0.] : 0.6666666666666666\n",
      "[1, 12, 19] : [0.] : 0.631578947368421\n",
      "[1, 13, 0] : [0.] : inf\n",
      "[1, 13, 1] : [0.] : 13.0\n",
      "[1, 13, 2] : [0.] : 6.5\n",
      "[1, 13, 3] : [0.] : 4.333333333333333\n",
      "[1, 13, 4] : [0.] : 3.25\n",
      "[1, 13, 5] : [0.] : 2.6\n",
      "[1, 13, 6] : [0.] : 2.1666666666666665\n",
      "[1, 13, 7] : [0.] : 1.8571428571428572\n",
      "[1, 13, 8] : [0.] : 1.625\n",
      "[1, 13, 9] : [0.] : 1.4444444444444444\n",
      "[1, 13, 10] : [0.] : 1.3\n",
      "[1, 13, 11] : [0.] : 1.1818181818181819\n",
      "[1, 13, 12] : [0.] : 1.0833333333333333\n",
      "[1, 13, 13] : [0.] : 1.0\n",
      "[1, 13, 14] : [0.] : 0.9285714285714286\n",
      "[1, 13, 15] : [0.] : 0.8666666666666667\n",
      "[1, 13, 16] : [0.] : 0.8125\n",
      "[1, 13, 17] : [0.] : 0.7647058823529411\n",
      "[1, 13, 18] : [0.] : 0.7222222222222222\n",
      "[1, 13, 19] : [0.] : 0.6842105263157895\n",
      "[1, 14, 0] : [0.] : inf\n",
      "[1, 14, 1] : [0.] : 14.0\n",
      "[1, 14, 2] : [0.] : 7.0\n",
      "[1, 14, 3] : [0.] : 4.666666666666667\n",
      "[1, 14, 4] : [0.] : 3.5\n",
      "[1, 14, 5] : [0.] : 2.8\n",
      "[1, 14, 6] : [0.] : 2.3333333333333335\n",
      "[1, 14, 7] : [0.] : 2.0\n",
      "[1, 14, 8] : [0.] : 1.75\n",
      "[1, 14, 9] : [0.] : 1.5555555555555556\n",
      "[1, 14, 10] : [0.] : 1.4\n",
      "[1, 14, 11] : [0.] : 1.2727272727272727\n",
      "[1, 14, 12] : [0.] : 1.1666666666666667\n",
      "[1, 14, 13] : [0.] : 1.0769230769230769\n",
      "[1, 14, 14] : [0.] : 1.0\n",
      "[1, 14, 15] : [0.] : 0.9333333333333333\n",
      "[1, 14, 16] : [0.] : 0.875\n",
      "[1, 14, 17] : [0.] : 0.8235294117647058\n",
      "[1, 14, 18] : [0.] : 0.7777777777777778\n",
      "[1, 14, 19] : [0.] : 0.7368421052631579\n",
      "[1, 15, 0] : [0.] : inf\n",
      "[1, 15, 1] : [0.] : 15.0\n",
      "[1, 15, 2] : [0.] : 7.5\n",
      "[1, 15, 3] : [0.] : 5.0\n",
      "[1, 15, 4] : [0.] : 3.75\n",
      "[1, 15, 5] : [0.] : 3.0\n",
      "[1, 15, 6] : [0.] : 2.5\n",
      "[1, 15, 7] : [0.] : 2.142857142857143\n",
      "[1, 15, 8] : [0.] : 1.875\n",
      "[1, 15, 9] : [0.] : 1.6666666666666667\n",
      "[1, 15, 10] : [0.] : 1.5\n",
      "[1, 15, 11] : [0.] : 1.3636363636363635\n",
      "[1, 15, 12] : [0.] : 1.25\n",
      "[1, 15, 13] : [0.] : 1.1538461538461537\n",
      "[1, 15, 14] : [0.] : 1.0714285714285714\n",
      "[1, 15, 15] : [0.] : 1.0\n",
      "[1, 15, 16] : [0.] : 0.9375\n",
      "[1, 15, 17] : [0.] : 0.8823529411764706\n",
      "[1, 15, 18] : [0.] : 0.8333333333333334\n",
      "[1, 15, 19] : [0.] : 0.7894736842105263\n",
      "[1, 16, 0] : [0.] : inf\n",
      "[1, 16, 1] : [0.] : 16.0\n",
      "[1, 16, 2] : [0.] : 8.0\n",
      "[1, 16, 3] : [0.] : 5.333333333333333\n",
      "[1, 16, 4] : [0.] : 4.0\n",
      "[1, 16, 5] : [0.] : 3.2\n",
      "[1, 16, 6] : [0.] : 2.6666666666666665\n",
      "[1, 16, 7] : [0.] : 2.2857142857142856\n",
      "[1, 16, 8] : [0.] : 2.0\n",
      "[1, 16, 9] : [0.] : 1.7777777777777777\n",
      "[1, 16, 10] : [0.] : 1.6\n",
      "[1, 16, 11] : [0.] : 1.4545454545454546\n",
      "[1, 16, 12] : [0.] : 1.3333333333333333\n",
      "[1, 16, 13] : [0.] : 1.2307692307692308\n",
      "[1, 16, 14] : [0.] : 1.1428571428571428\n",
      "[1, 16, 15] : [0.] : 1.0666666666666667\n",
      "[1, 16, 16] : [0.] : 1.0\n",
      "[1, 16, 17] : [0.] : 0.9411764705882353\n",
      "[1, 16, 18] : [0.] : 0.8888888888888888\n",
      "[1, 16, 19] : [0.] : 0.8421052631578947\n",
      "[1, 17, 0] : [0.] : inf\n",
      "[1, 17, 1] : [0.] : 17.0\n",
      "[1, 17, 2] : [0.] : 8.5\n",
      "[1, 17, 3] : [0.] : 5.666666666666667\n",
      "[1, 17, 4] : [0.] : 4.25\n",
      "[1, 17, 5] : [0.] : 3.4\n",
      "[1, 17, 6] : [0.] : 2.8333333333333335\n",
      "[1, 17, 7] : [0.] : 2.4285714285714284\n",
      "[1, 17, 8] : [0.] : 2.125\n",
      "[1, 17, 9] : [0.] : 1.8888888888888888\n",
      "[1, 17, 10] : [0.] : 1.7\n",
      "[1, 17, 11] : [0.] : 1.5454545454545454\n",
      "[1, 17, 12] : [0.] : 1.4166666666666667\n",
      "[1, 17, 13] : [0.] : 1.3076923076923077\n",
      "[1, 17, 14] : [0.] : 1.2142857142857142\n",
      "[1, 17, 15] : [0.] : 1.1333333333333333\n",
      "[1, 17, 16] : [0.] : 1.0625\n",
      "[1, 17, 17] : [0.] : 1.0\n",
      "[1, 17, 18] : [0.] : 0.9444444444444444\n",
      "[1, 17, 19] : [0.] : 0.8947368421052632\n",
      "[1, 18, 0] : [0.] : inf\n",
      "[1, 18, 1] : [0.] : 18.0\n",
      "[1, 18, 2] : [0.] : 9.0\n",
      "[1, 18, 3] : [0.] : 6.0\n",
      "[1, 18, 4] : [0.] : 4.5\n",
      "[1, 18, 5] : [0.] : 3.6\n",
      "[1, 18, 6] : [0.] : 3.0\n",
      "[1, 18, 7] : [0.] : 2.5714285714285716\n",
      "[1, 18, 8] : [0.] : 2.25\n",
      "[1, 18, 9] : [0.] : 2.0\n",
      "[1, 18, 10] : [0.] : 1.8\n",
      "[1, 18, 11] : [0.] : 1.6363636363636365\n",
      "[1, 18, 12] : [0.] : 1.5\n",
      "[1, 18, 13] : [0.] : 1.3846153846153846\n",
      "[1, 18, 14] : [0.] : 1.2857142857142858\n",
      "[1, 18, 15] : [0.] : 1.2\n",
      "[1, 18, 16] : [0.] : 1.125\n",
      "[1, 18, 17] : [0.] : 1.0588235294117647\n",
      "[1, 18, 18] : [0.] : 1.0\n",
      "[1, 18, 19] : [0.] : 0.9473684210526315\n",
      "[1, 19, 0] : [0.] : inf\n",
      "[1, 19, 1] : [0.] : 19.0\n",
      "[1, 19, 2] : [0.] : 9.5\n",
      "[1, 19, 3] : [0.] : 6.333333333333333\n",
      "[1, 19, 4] : [0.] : 4.75\n",
      "[1, 19, 5] : [0.] : 3.8\n",
      "[1, 19, 6] : [0.] : 3.1666666666666665\n",
      "[1, 19, 7] : [0.] : 2.7142857142857144\n",
      "[1, 19, 8] : [0.] : 2.375\n",
      "[1, 19, 9] : [0.] : 2.111111111111111\n",
      "[1, 19, 10] : [0.] : 1.9\n",
      "[1, 19, 11] : [0.] : 1.7272727272727273\n",
      "[1, 19, 12] : [0.] : 1.5833333333333333\n",
      "[1, 19, 13] : [0.] : 1.4615384615384615\n",
      "[1, 19, 14] : [0.] : 1.3571428571428572\n",
      "[1, 19, 15] : [0.] : 1.2666666666666666\n",
      "[1, 19, 16] : [0.] : 1.1875\n",
      "[1, 19, 17] : [0.] : 1.1176470588235294\n",
      "[1, 19, 18] : [0.] : 1.0555555555555556\n",
      "[1, 19, 19] : [0.] : 1.0\n",
      "[2, 0, 0] : [0.] : inf\n",
      "[2, 0, 1] : [0.] : inf\n",
      "[2, 0, 2] : [0.] : inf\n",
      "[2, 0, 3] : [0.] : inf\n",
      "[2, 0, 4] : [0.] : inf\n",
      "[2, 0, 5] : [0.] : inf\n",
      "[2, 0, 6] : [0.] : inf\n",
      "[2, 0, 7] : [0.] : inf\n",
      "[2, 0, 8] : [0.] : inf\n",
      "[2, 0, 9] : [0.] : inf\n",
      "[2, 0, 10] : [0.] : inf\n",
      "[2, 0, 11] : [0.] : inf\n",
      "[2, 0, 12] : [0.] : inf\n",
      "[2, 0, 13] : [0.] : inf\n",
      "[2, 0, 14] : [0.] : inf\n",
      "[2, 0, 15] : [0.] : inf\n",
      "[2, 0, 16] : [0.] : inf\n",
      "[2, 0, 17] : [0.] : inf\n",
      "[2, 0, 18] : [0.] : inf\n",
      "[2, 0, 19] : [0.] : inf\n",
      "[2, 1, 0] : [0.] : 0.0\n",
      "[2, 1, 1] : [0.] : 1.0\n",
      "[2, 1, 2] : [0.] : 2.0\n",
      "[2, 1, 3] : [0.] : 3.0\n",
      "[2, 1, 4] : [0.] : 4.0\n",
      "[2, 1, 5] : [0.] : 5.0\n",
      "[2, 1, 6] : [0.] : 6.0\n",
      "[2, 1, 7] : [0.] : 7.0\n",
      "[2, 1, 8] : [0.] : 8.0\n",
      "[2, 1, 9] : [0.] : 9.0\n",
      "[2, 1, 10] : [0.] : 10.0\n",
      "[2, 1, 11] : [0.] : 11.0\n",
      "[2, 1, 12] : [0.] : 12.0\n",
      "[2, 1, 13] : [0.] : 13.0\n",
      "[2, 1, 14] : [0.] : 14.0\n",
      "[2, 1, 15] : [0.] : 15.0\n",
      "[2, 1, 16] : [0.] : 16.0\n",
      "[2, 1, 17] : [0.] : 17.0\n",
      "[2, 1, 18] : [0.] : 18.0\n",
      "[2, 1, 19] : [0.] : 19.0\n",
      "[2, 2, 0] : [0.] : 0.0\n",
      "[2, 2, 1] : [0.] : 0.5\n",
      "[2, 2, 2] : [0.] : 1.0\n",
      "[2, 2, 3] : [0.] : 1.5\n",
      "[2, 2, 4] : [0.] : 2.0\n",
      "[2, 2, 5] : [0.] : 2.5\n",
      "[2, 2, 6] : [0.] : 3.0\n",
      "[2, 2, 7] : [0.] : 3.5\n",
      "[2, 2, 8] : [0.] : 4.0\n",
      "[2, 2, 9] : [0.] : 4.5\n",
      "[2, 2, 10] : [0.] : 5.0\n",
      "[2, 2, 11] : [0.] : 5.5\n",
      "[2, 2, 12] : [0.] : 6.0\n",
      "[2, 2, 13] : [0.] : 6.5\n",
      "[2, 2, 14] : [0.] : 7.0\n",
      "[2, 2, 15] : [0.] : 7.5\n",
      "[2, 2, 16] : [0.] : 8.0\n",
      "[2, 2, 17] : [0.] : 8.5\n",
      "[2, 2, 18] : [0.] : 9.0\n",
      "[2, 2, 19] : [0.] : 9.5\n",
      "[2, 3, 0] : [0.] : 0.0\n",
      "[2, 3, 1] : [0.] : 0.3333333333333333\n",
      "[2, 3, 2] : [0.] : 0.6666666666666666\n",
      "[2, 3, 3] : [0.] : 1.0\n",
      "[2, 3, 4] : [0.] : 1.3333333333333333\n",
      "[2, 3, 5] : [0.] : 1.6666666666666667\n",
      "[2, 3, 6] : [0.] : 2.0\n",
      "[2, 3, 7] : [0.] : 2.3333333333333335\n",
      "[2, 3, 8] : [0.] : 2.6666666666666665\n",
      "[2, 3, 9] : [0.] : 3.0\n",
      "[2, 3, 10] : [0.] : 3.3333333333333335\n",
      "[2, 3, 11] : [0.] : 3.6666666666666665\n",
      "[2, 3, 12] : [0.] : 4.0\n",
      "[2, 3, 13] : [0.] : 4.333333333333333\n",
      "[2, 3, 14] : [0.] : 4.666666666666667\n",
      "[2, 3, 15] : [0.] : 5.0\n",
      "[2, 3, 16] : [0.] : 5.333333333333333\n",
      "[2, 3, 17] : [0.] : 5.666666666666667\n",
      "[2, 3, 18] : [0.] : 6.0\n",
      "[2, 3, 19] : [0.] : 6.333333333333333\n",
      "[2, 4, 0] : [0.] : 0.0\n",
      "[2, 4, 1] : [0.] : 0.25\n",
      "[2, 4, 2] : [0.] : 0.5\n",
      "[2, 4, 3] : [0.] : 0.75\n",
      "[2, 4, 4] : [0.] : 1.0\n",
      "[2, 4, 5] : [0.] : 1.25\n",
      "[2, 4, 6] : [0.] : 1.5\n",
      "[2, 4, 7] : [0.] : 1.75\n",
      "[2, 4, 8] : [0.] : 2.0\n",
      "[2, 4, 9] : [0.] : 2.25\n",
      "[2, 4, 10] : [0.] : 2.5\n",
      "[2, 4, 11] : [0.] : 2.75\n",
      "[2, 4, 12] : [0.] : 3.0\n",
      "[2, 4, 13] : [0.] : 3.25\n",
      "[2, 4, 14] : [0.] : 3.5\n",
      "[2, 4, 15] : [0.] : 3.75\n",
      "[2, 4, 16] : [0.] : 4.0\n",
      "[2, 4, 17] : [0.] : 4.25\n",
      "[2, 4, 18] : [0.] : 4.5\n",
      "[2, 4, 19] : [0.] : 4.75\n",
      "[2, 5, 0] : [0.] : 0.0\n",
      "[2, 5, 1] : [0.] : 0.2\n",
      "[2, 5, 2] : [0.] : 0.4\n",
      "[2, 5, 3] : [0.] : 0.6\n",
      "[2, 5, 4] : [0.] : 0.8\n",
      "[2, 5, 5] : [0.] : 1.0\n",
      "[2, 5, 6] : [0.] : 1.2\n",
      "[2, 5, 7] : [0.] : 1.4\n",
      "[2, 5, 8] : [0.] : 1.6\n",
      "[2, 5, 9] : [0.] : 1.8\n",
      "[2, 5, 10] : [0.] : 2.0\n",
      "[2, 5, 11] : [0.] : 2.2\n",
      "[2, 5, 12] : [0.] : 2.4\n",
      "[2, 5, 13] : [0.] : 2.6\n",
      "[2, 5, 14] : [0.] : 2.8\n",
      "[2, 5, 15] : [0.] : 3.0\n",
      "[2, 5, 16] : [0.] : 3.2\n",
      "[2, 5, 17] : [0.] : 3.4\n",
      "[2, 5, 18] : [0.] : 3.6\n",
      "[2, 5, 19] : [0.] : 3.8\n",
      "[2, 6, 0] : [0.] : 0.0\n",
      "[2, 6, 1] : [0.] : 0.16666666666666666\n",
      "[2, 6, 2] : [0.] : 0.3333333333333333\n",
      "[2, 6, 3] : [0.] : 0.5\n",
      "[2, 6, 4] : [0.] : 0.6666666666666666\n",
      "[2, 6, 5] : [0.] : 0.8333333333333334\n",
      "[2, 6, 6] : [0.] : 1.0\n",
      "[2, 6, 7] : [0.] : 1.1666666666666667\n",
      "[2, 6, 8] : [0.] : 1.3333333333333333\n",
      "[2, 6, 9] : [0.] : 1.5\n",
      "[2, 6, 10] : [0.] : 1.6666666666666667\n",
      "[2, 6, 11] : [0.] : 1.8333333333333333\n",
      "[2, 6, 12] : [0.] : 2.0\n",
      "[2, 6, 13] : [0.] : 2.1666666666666665\n",
      "[2, 6, 14] : [0.] : 2.3333333333333335\n",
      "[2, 6, 15] : [0.] : 2.5\n",
      "[2, 6, 16] : [0.] : 2.6666666666666665\n",
      "[2, 6, 17] : [0.] : 2.8333333333333335\n",
      "[2, 6, 18] : [0.] : 3.0\n",
      "[2, 6, 19] : [0.] : 3.1666666666666665\n",
      "[2, 7, 0] : [0.] : 0.0\n",
      "[2, 7, 1] : [0.] : 0.14285714285714285\n",
      "[2, 7, 2] : [0.] : 0.2857142857142857\n",
      "[2, 7, 3] : [0.] : 0.42857142857142855\n",
      "[2, 7, 4] : [0.] : 0.5714285714285714\n",
      "[2, 7, 5] : [0.] : 0.7142857142857143\n",
      "[2, 7, 6] : [0.] : 0.8571428571428571\n",
      "[2, 7, 7] : [0.] : 1.0\n",
      "[2, 7, 8] : [0.] : 1.1428571428571428\n",
      "[2, 7, 9] : [0.] : 1.2857142857142858\n",
      "[2, 7, 10] : [0.] : 1.4285714285714286\n",
      "[2, 7, 11] : [0.] : 1.5714285714285714\n",
      "[2, 7, 12] : [0.] : 1.7142857142857142\n",
      "[2, 7, 13] : [0.] : 1.8571428571428572\n",
      "[2, 7, 14] : [0.] : 2.0\n",
      "[2, 7, 15] : [0.] : 2.142857142857143\n",
      "[2, 7, 16] : [0.] : 2.2857142857142856\n",
      "[2, 7, 17] : [0.] : 2.4285714285714284\n",
      "[2, 7, 18] : [0.] : 2.5714285714285716\n",
      "[2, 7, 19] : [0.] : 2.7142857142857144\n",
      "[2, 8, 0] : [0.] : 0.0\n",
      "[2, 8, 1] : [0.] : 0.125\n",
      "[2, 8, 2] : [0.] : 0.25\n",
      "[2, 8, 3] : [0.] : 0.375\n",
      "[2, 8, 4] : [0.] : 0.5\n",
      "[2, 8, 5] : [0.] : 0.625\n",
      "[2, 8, 6] : [0.] : 0.75\n",
      "[2, 8, 7] : [0.] : 0.875\n",
      "[2, 8, 8] : [0.] : 1.0\n",
      "[2, 8, 9] : [0.] : 1.125\n",
      "[2, 8, 10] : [0.] : 1.25\n",
      "[2, 8, 11] : [0.] : 1.375\n",
      "[2, 8, 12] : [0.] : 1.5\n",
      "[2, 8, 13] : [0.] : 1.625\n",
      "[2, 8, 14] : [0.] : 1.75\n",
      "[2, 8, 15] : [0.] : 1.875\n",
      "[2, 8, 16] : [0.] : 2.0\n",
      "[2, 8, 17] : [0.] : 2.125\n",
      "[2, 8, 18] : [0.] : 2.25\n",
      "[2, 8, 19] : [0.] : 2.375\n",
      "[2, 9, 0] : [0.] : 0.0\n",
      "[2, 9, 1] : [0.] : 0.1111111111111111\n",
      "[2, 9, 2] : [0.] : 0.2222222222222222\n",
      "[2, 9, 3] : [0.] : 0.3333333333333333\n",
      "[2, 9, 4] : [0.] : 0.4444444444444444\n",
      "[2, 9, 5] : [0.] : 0.5555555555555556\n",
      "[2, 9, 6] : [0.] : 0.6666666666666666\n",
      "[2, 9, 7] : [0.] : 0.7777777777777778\n",
      "[2, 9, 8] : [0.] : 0.8888888888888888\n",
      "[2, 9, 9] : [0.] : 1.0\n",
      "[2, 9, 10] : [0.] : 1.1111111111111112\n",
      "[2, 9, 11] : [0.] : 1.2222222222222223\n",
      "[2, 9, 12] : [0.] : 1.3333333333333333\n",
      "[2, 9, 13] : [0.] : 1.4444444444444444\n",
      "[2, 9, 14] : [0.] : 1.5555555555555556\n",
      "[2, 9, 15] : [0.] : 1.6666666666666667\n",
      "[2, 9, 16] : [0.] : 1.7777777777777777\n",
      "[2, 9, 17] : [0.] : 1.8888888888888888\n",
      "[2, 9, 18] : [0.] : 2.0\n",
      "[2, 9, 19] : [0.] : 2.111111111111111\n",
      "[2, 10, 0] : [0.] : 0.0\n",
      "[2, 10, 1] : [0.] : 0.1\n",
      "[2, 10, 2] : [0.] : 0.2\n",
      "[2, 10, 3] : [0.] : 0.3\n",
      "[2, 10, 4] : [0.] : 0.4\n",
      "[2, 10, 5] : [0.] : 0.5\n",
      "[2, 10, 6] : [0.] : 0.6\n",
      "[2, 10, 7] : [0.] : 0.7\n",
      "[2, 10, 8] : [0.] : 0.8\n",
      "[2, 10, 9] : [0.] : 0.9\n",
      "[2, 10, 10] : [0.] : 1.0\n",
      "[2, 10, 11] : [0.] : 1.1\n",
      "[2, 10, 12] : [0.] : 1.2\n",
      "[2, 10, 13] : [0.] : 1.3\n",
      "[2, 10, 14] : [0.] : 1.4\n",
      "[2, 10, 15] : [0.] : 1.5\n",
      "[2, 10, 16] : [0.] : 1.6\n",
      "[2, 10, 17] : [0.] : 1.7\n",
      "[2, 10, 18] : [0.] : 1.8\n",
      "[2, 10, 19] : [0.] : 1.9\n",
      "[2, 11, 0] : [0.] : 0.0\n",
      "[2, 11, 1] : [0.] : 0.09090909090909091\n",
      "[2, 11, 2] : [0.] : 0.18181818181818182\n",
      "[2, 11, 3] : [0.] : 0.2727272727272727\n",
      "[2, 11, 4] : [0.] : 0.36363636363636365\n",
      "[2, 11, 5] : [0.] : 0.45454545454545453\n",
      "[2, 11, 6] : [0.] : 0.5454545454545454\n",
      "[2, 11, 7] : [0.] : 0.6363636363636364\n",
      "[2, 11, 8] : [0.] : 0.7272727272727273\n",
      "[2, 11, 9] : [0.] : 0.8181818181818182\n",
      "[2, 11, 10] : [0.] : 0.9090909090909091\n",
      "[2, 11, 11] : [0.] : 1.0\n",
      "[2, 11, 12] : [0.] : 1.0909090909090908\n",
      "[2, 11, 13] : [0.] : 1.1818181818181819\n",
      "[2, 11, 14] : [0.] : 1.2727272727272727\n",
      "[2, 11, 15] : [0.] : 1.3636363636363635\n",
      "[2, 11, 16] : [0.] : 1.4545454545454546\n",
      "[2, 11, 17] : [0.] : 1.5454545454545454\n",
      "[2, 11, 18] : [0.] : 1.6363636363636365\n",
      "[2, 11, 19] : [0.] : 1.7272727272727273\n",
      "[2, 12, 0] : [0.] : 0.0\n",
      "[2, 12, 1] : [0.] : 0.08333333333333333\n",
      "[2, 12, 2] : [0.] : 0.16666666666666666\n",
      "[2, 12, 3] : [0.] : 0.25\n",
      "[2, 12, 4] : [0.] : 0.3333333333333333\n",
      "[2, 12, 5] : [0.] : 0.4166666666666667\n",
      "[2, 12, 6] : [0.] : 0.5\n",
      "[2, 12, 7] : [0.] : 0.5833333333333334\n",
      "[2, 12, 8] : [0.] : 0.6666666666666666\n",
      "[2, 12, 9] : [0.] : 0.75\n",
      "[2, 12, 10] : [0.] : 0.8333333333333334\n",
      "[2, 12, 11] : [0.] : 0.9166666666666666\n",
      "[2, 12, 12] : [0.] : 1.0\n",
      "[2, 12, 13] : [0.] : 1.0833333333333333\n",
      "[2, 12, 14] : [0.] : 1.1666666666666667\n",
      "[2, 12, 15] : [0.] : 1.25\n",
      "[2, 12, 16] : [0.] : 1.3333333333333333\n",
      "[2, 12, 17] : [0.] : 1.4166666666666667\n",
      "[2, 12, 18] : [0.] : 1.5\n",
      "[2, 12, 19] : [0.] : 1.5833333333333333\n",
      "[2, 13, 0] : [0.] : 0.0\n",
      "[2, 13, 1] : [0.] : 0.07692307692307693\n",
      "[2, 13, 2] : [0.] : 0.15384615384615385\n",
      "[2, 13, 3] : [0.] : 0.23076923076923078\n",
      "[2, 13, 4] : [0.] : 0.3076923076923077\n",
      "[2, 13, 5] : [0.] : 0.38461538461538464\n",
      "[2, 13, 6] : [0.] : 0.46153846153846156\n",
      "[2, 13, 7] : [0.] : 0.5384615384615384\n",
      "[2, 13, 8] : [0.] : 0.6153846153846154\n",
      "[2, 13, 9] : [0.] : 0.6923076923076923\n",
      "[2, 13, 10] : [0.] : 0.7692307692307693\n",
      "[2, 13, 11] : [0.] : 0.8461538461538461\n",
      "[2, 13, 12] : [0.] : 0.9230769230769231\n",
      "[2, 13, 13] : [0.] : 1.0\n",
      "[2, 13, 14] : [0.] : 1.0769230769230769\n",
      "[2, 13, 15] : [0.] : 1.1538461538461537\n",
      "[2, 13, 16] : [0.] : 1.2307692307692308\n",
      "[2, 13, 17] : [0.] : 1.3076923076923077\n",
      "[2, 13, 18] : [0.] : 1.3846153846153846\n",
      "[2, 13, 19] : [0.] : 1.4615384615384615\n",
      "[2, 14, 0] : [0.] : 0.0\n",
      "[2, 14, 1] : [0.] : 0.07142857142857142\n",
      "[2, 14, 2] : [0.] : 0.14285714285714285\n",
      "[2, 14, 3] : [0.] : 0.21428571428571427\n",
      "[2, 14, 4] : [0.] : 0.2857142857142857\n",
      "[2, 14, 5] : [0.] : 0.35714285714285715\n",
      "[2, 14, 6] : [0.] : 0.42857142857142855\n",
      "[2, 14, 7] : [0.] : 0.5\n",
      "[2, 14, 8] : [0.] : 0.5714285714285714\n",
      "[2, 14, 9] : [0.] : 0.6428571428571429\n",
      "[2, 14, 10] : [0.] : 0.7142857142857143\n",
      "[2, 14, 11] : [0.] : 0.7857142857142857\n",
      "[2, 14, 12] : [0.] : 0.8571428571428571\n",
      "[2, 14, 13] : [0.] : 0.9285714285714286\n",
      "[2, 14, 14] : [0.] : 1.0\n",
      "[2, 14, 15] : [0.] : 1.0714285714285714\n",
      "[2, 14, 16] : [0.] : 1.1428571428571428\n",
      "[2, 14, 17] : [0.] : 1.2142857142857142\n",
      "[2, 14, 18] : [0.] : 1.2857142857142858\n",
      "[2, 14, 19] : [0.] : 1.3571428571428572\n",
      "[2, 15, 0] : [0.] : 0.0\n",
      "[2, 15, 1] : [0.] : 0.06666666666666667\n",
      "[2, 15, 2] : [0.] : 0.13333333333333333\n",
      "[2, 15, 3] : [0.] : 0.2\n",
      "[2, 15, 4] : [0.] : 0.26666666666666666\n",
      "[2, 15, 5] : [0.] : 0.3333333333333333\n",
      "[2, 15, 6] : [0.] : 0.4\n",
      "[2, 15, 7] : [0.] : 0.4666666666666667\n",
      "[2, 15, 8] : [0.] : 0.5333333333333333\n",
      "[2, 15, 9] : [0.] : 0.6\n",
      "[2, 15, 10] : [0.] : 0.6666666666666666\n",
      "[2, 15, 11] : [0.] : 0.7333333333333333\n",
      "[2, 15, 12] : [0.] : 0.8\n",
      "[2, 15, 13] : [0.] : 0.8666666666666667\n",
      "[2, 15, 14] : [0.] : 0.9333333333333333\n",
      "[2, 15, 15] : [0.] : 1.0\n",
      "[2, 15, 16] : [0.] : 1.0666666666666667\n",
      "[2, 15, 17] : [0.] : 1.1333333333333333\n",
      "[2, 15, 18] : [0.] : 1.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 15, 19] : [0.] : 1.2666666666666666\n",
      "[2, 16, 0] : [0.] : 0.0\n",
      "[2, 16, 1] : [0.] : 0.0625\n",
      "[2, 16, 2] : [0.] : 0.125\n",
      "[2, 16, 3] : [0.] : 0.1875\n",
      "[2, 16, 4] : [0.] : 0.25\n",
      "[2, 16, 5] : [0.] : 0.3125\n",
      "[2, 16, 6] : [0.] : 0.375\n",
      "[2, 16, 7] : [0.] : 0.4375\n",
      "[2, 16, 8] : [0.] : 0.5\n",
      "[2, 16, 9] : [0.] : 0.5625\n",
      "[2, 16, 10] : [0.] : 0.625\n",
      "[2, 16, 11] : [0.] : 0.6875\n",
      "[2, 16, 12] : [0.] : 0.75\n",
      "[2, 16, 13] : [0.] : 0.8125\n",
      "[2, 16, 14] : [0.] : 0.875\n",
      "[2, 16, 15] : [0.] : 0.9375\n",
      "[2, 16, 16] : [0.] : 1.0\n",
      "[2, 16, 17] : [0.] : 1.0625\n",
      "[2, 16, 18] : [0.] : 1.125\n",
      "[2, 16, 19] : [0.] : 1.1875\n",
      "[2, 17, 0] : [0.] : 0.0\n",
      "[2, 17, 1] : [0.] : 0.058823529411764705\n",
      "[2, 17, 2] : [0.] : 0.11764705882352941\n",
      "[2, 17, 3] : [0.] : 0.17647058823529413\n",
      "[2, 17, 4] : [0.] : 0.23529411764705882\n",
      "[2, 17, 5] : [0.] : 0.29411764705882354\n",
      "[2, 17, 6] : [0.] : 0.35294117647058826\n",
      "[2, 17, 7] : [0.] : 0.4117647058823529\n",
      "[2, 17, 8] : [0.] : 0.47058823529411764\n",
      "[2, 17, 9] : [0.] : 0.5294117647058824\n",
      "[2, 17, 10] : [0.] : 0.5882352941176471\n",
      "[2, 17, 11] : [0.] : 0.6470588235294118\n",
      "[2, 17, 12] : [0.] : 0.7058823529411765\n",
      "[2, 17, 13] : [0.] : 0.7647058823529411\n",
      "[2, 17, 14] : [0.] : 0.8235294117647058\n",
      "[2, 17, 15] : [0.] : 0.8823529411764706\n",
      "[2, 17, 16] : [0.] : 0.9411764705882353\n",
      "[2, 17, 17] : [0.] : 1.0\n",
      "[2, 17, 18] : [0.] : 1.0588235294117647\n",
      "[2, 17, 19] : [0.] : 1.1176470588235294\n",
      "[2, 18, 0] : [0.] : 0.0\n",
      "[2, 18, 1] : [0.] : 0.05555555555555555\n",
      "[2, 18, 2] : [0.] : 0.1111111111111111\n",
      "[2, 18, 3] : [0.] : 0.16666666666666666\n",
      "[2, 18, 4] : [0.] : 0.2222222222222222\n",
      "[2, 18, 5] : [0.] : 0.2777777777777778\n",
      "[2, 18, 6] : [0.] : 0.3333333333333333\n",
      "[2, 18, 7] : [0.] : 0.3888888888888889\n",
      "[2, 18, 8] : [0.] : 0.4444444444444444\n",
      "[2, 18, 9] : [0.] : 0.5\n",
      "[2, 18, 10] : [0.] : 0.5555555555555556\n",
      "[2, 18, 11] : [0.] : 0.6111111111111112\n",
      "[2, 18, 12] : [0.] : 0.6666666666666666\n",
      "[2, 18, 13] : [0.] : 0.7222222222222222\n",
      "[2, 18, 14] : [0.] : 0.7777777777777778\n",
      "[2, 18, 15] : [0.] : 0.8333333333333334\n",
      "[2, 18, 16] : [0.] : 0.8888888888888888\n",
      "[2, 18, 17] : [0.] : 0.9444444444444444\n",
      "[2, 18, 18] : [0.] : 1.0\n",
      "[2, 18, 19] : [0.] : 1.0555555555555556\n",
      "[2, 19, 0] : [0.] : 0.0\n",
      "[2, 19, 1] : [0.] : 0.05263157894736842\n",
      "[2, 19, 2] : [0.] : 0.10526315789473684\n",
      "[2, 19, 3] : [0.] : 0.15789473684210525\n",
      "[2, 19, 4] : [0.] : 0.21052631578947367\n",
      "[2, 19, 5] : [0.] : 0.2631578947368421\n",
      "[2, 19, 6] : [0.] : 0.3157894736842105\n",
      "[2, 19, 7] : [0.] : 0.3684210526315789\n",
      "[2, 19, 8] : [0.] : 0.42105263157894735\n",
      "[2, 19, 9] : [0.] : 0.47368421052631576\n",
      "[2, 19, 10] : [0.] : 0.5263157894736842\n",
      "[2, 19, 11] : [0.] : 0.5789473684210527\n",
      "[2, 19, 12] : [0.] : 0.631578947368421\n",
      "[2, 19, 13] : [0.] : 0.6842105263157895\n",
      "[2, 19, 14] : [0.] : 0.7368421052631579\n",
      "[2, 19, 15] : [0.] : 0.7894736842105263\n",
      "[2, 19, 16] : [0.] : 0.8421052631578947\n",
      "[2, 19, 17] : [0.] : 0.8947368421052632\n",
      "[2, 19, 18] : [0.] : 0.9473684210526315\n",
      "[2, 19, 19] : [0.] : 1.0\n"
     ]
    }
   ],
   "source": [
    "for xi,zi,yi in zip(x,z,y):\n",
    "    print(f'{xi} : {zi} : {yi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (FastAI)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
